<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy</title><link>http://openastronomy.org/Universe_OA/</link><description>This is an aggregator of openastronomy people</description><atom:link href="http://openastronomy.org/Universe_OA/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Mon, 08 Aug 2022 16:38:47 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Advanced options</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220731_0000_arunavabasu-03/</link><dc:creator>arunavabasu-03</dc:creator><description>&lt;p&gt;Impove default resolution of ploted spectrum In  wstep = “auto”  radis app gives slitly low res. for that reasons plotted  spectrum  is…&lt;/p&gt;
&lt;div style="margin-top: 50px; font-style: italic;"&gt;&lt;strong&gt;&lt;a href="https://minimal-blog.lekoarts.de/6thweek/"&gt;Keep reading&lt;/a&gt;.&lt;/strong&gt;&lt;/div&gt;&lt;br&gt; &lt;br&gt;
&lt;!-- TEASER_END --&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220731_0000_arunavabasu-03/</guid><pubDate>Sat, 30 Jul 2022 23:00:00 GMT</pubDate></item><item><title>GSoC Blog#2</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220726_0559_aman-pandey-afk/</link><dc:creator>AMAN PANDEY</dc:creator><description>&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/680/1*dfjiDfMcY8h9eEOySAnxbA.jpeg"&gt;&lt;/figure&gt;&lt;p&gt;The first half of the coding period is almost done, and here I am with the updates! As stated at the end of the last blog, I started the 3rd week by improving the &lt;a href="https://github.com/StingraySoftware/Stingray.jl/pull/2"&gt;second PR&lt;/a&gt;. I performed pretty intensive memory and performance analysis on the functions in fourier.jl, using BenchmarkTools and .mem files to analyze bottlenecks in the program. With my mentors’ help, I removed many allocation and type-stability related issues during that time. I also had some problems with non-idiomatic code, like I could use multiple-dispatch or dot broadcast in functions, some of which I solved, and some are due for refactoring after the mid-evaluation. After finishing the improvements and getting my second PR merged, I planned to work on LightCurves and implement periodograms and other APIs so that users can easily manipulate photon count data. But my mentor suggested I implement file reading and mechanisms to manage the GTIs (Good Time Intervals) obtained from these files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Working out the GTI mechanisms&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I had learned a lot from the previous PR, and one of the things was I should try to implement some of the methods in my way rather than using the python algorithms with an idiomatic Julian code in mind. I started the 4th week with methods for reading GTIs from a FITS file (For those unfamiliar, it is a file format for storing, processing, and transmitting scientific data, especially images). I used the FITSIO.jl package, and experimenting on the terminal led me to manipulate HDUs and their data. One thing I thoroughly thought of was the appropriate data structure of the GTIs. Should I use Intervals from the Intervals.jl package? Or a vector of vector like the python library does? I finally decided to use what I was using in the fourier.jl, an AbstractMatrix of Reals. It was easy to access data from them, and you could use slices to get a list of start and end times. For the operations, I had to convert among matrix, intervals frequently, and vectors as the Intervals.jl provided many ways to manipulate GTIs like union or intersection or getting its complement, i.e., Bad Time Intervals. With some more methods like creating masks and GTIs from conditions and implementing Tests for all of these functions, I was finished with the gti.jl file. A little performance analysis told me that the code was efficient. After some refactoring, like removing code duplication by merging union and intersection in the same function, I was done with the PR. It has some minor changes currently to be made before it gets merged.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;&lt;strong&gt;Working on the documentation&lt;/strong&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lbM1DS0_-Ja0lb53Owb6PQ.png"&gt;&lt;/figure&gt;&lt;p&gt;As the mid evaluations have begun this week, I will be taking some time to write the docstring and deploy them on GitHub. The stingray python docs are pretty good, so I will mostly use them as a Base and tweak them as necessary (when there is a different function signature or the Julian way of doing things is different). Documenter.jl will be the package I would be using for this. The complete documentation will be a milestone for the end of the program, where I, along with my mentors, will try to write notebook tutorials for the package and host them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For the second phase&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I hope to qualify for the mid-evals, after which the second phase will begin. The core implementation is done; users can now use the library and its different methods to read from a file, process the data, and create periodograms. The main motive now will be to ease its access and implement other helpful features, a major one of which will be plotting the periodograms. I initially proposed working with these APIs before mid-evals, but who knows about the future? I have done some things meant for the other half, so I guess it’s okay. As an end note, I am pretty much excited for the other half of this program, it has made me learn a lot, and the workings of Julia awe-inspire me as I explore it side by side. Goodbye for now!&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=63d283e1a60b" width="1"&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220726_0559_aman-pandey-afk/</guid><pubDate>Tue, 26 Jul 2022 04:59:13 GMT</pubDate></item><item><title>GSoC @ Stingray: Diving into coding period. blog #2</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220724_1811_mihirtripathi97/</link><dc:creator>Mihirtripathi</dc:creator><description>&lt;p&gt;Hey there!&lt;/p&gt;
&lt;p&gt;It is time to write a blog about my experience in the coding period so far. So here it goes.&lt;/p&gt;
&lt;p&gt;The official coding period for GSoC’22 started on the 13th of June. After discussing with mentors I decided that the first task would be to create a base structure of the code for Bexvar. As the method was already implemented by Dr. Johannes Buchner (who also suggested implementing this method in Stingray)and David Bogensberger, we decided to use this &lt;a href="https://github.com/JohannesBuchner/bexvar"&gt;implementation&lt;/a&gt; as a reference.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I spent the first 2–3 days planning the structure of the code and planning its implementation in Stingray’s code base. At first, the implementation seemed easy. Although as I explored more and discussed my ideas with my mentors I realized that there are many small but important changes that need to be made.&lt;/p&gt;
&lt;p&gt;In addition to these, I realized that I had to set up a proper environment on my computer to write, edit and test the codes that I write. I decided to use &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; (VS Code) for it. Before the contribution period, I had only a little familiarity with Github and had never used git in my local system. I somehow made it through the contribution period without installing it. Now since I had an open source project at hand which will require frequent commits, I decided to install git and GitHub desktop on my computer and learn to use git with CLI. I found out that along with many useful tools for professional programming, VS Code also provided support to use git inside from the editor, this seemed quite useful for my purpose. I learned how to install and work with multiple versions of Python. I learned how to set up a Python virtual environment and use it to test codes in a controlled environment. I had to go through multiple iterations of installing, uninstalling, and then reinstalling several packages to set everything perfectly. This made me a bit irritated but later on, I realized that this helped me save a lot of time while coding for the project.&lt;/p&gt;
&lt;p&gt;After going through a few iterations the base code was ready and working. It still needed some improvements and structural changes. It had a core function that reads the light curve data from an AstroPy table. After that, it would call internal functions successively to finally obtain the Bayesian Excess Variance of count rate. My mentor Prof. Matteo suggested that I start a PR with this version of the code. As I made this &lt;a href="https://github.com/StingraySoftware/stingray/pull/664"&gt;PR&lt;/a&gt;, we started discussing how to improve the code.&lt;/p&gt;
&lt;p&gt;My mentors pointed out that my core function &lt;em&gt;bexvar()&lt;/em&gt; needed further modularization. We decided to separate it into two functions, A core function &lt;em&gt;bexvar()&lt;/em&gt; which will accept light curve data as a set of NumPy arrays or lists and calculate bexvar, and a &lt;em&gt;bexvar_from_table()&lt;/em&gt; function which can read light curve data from an AstroPy table and call &lt;em&gt;bexvar()&lt;/em&gt;. This change made the core &lt;em&gt;bexvar()&lt;/em&gt; function more general as now users would not need to have light curve data in form of an AstroPy Table object to obtain bexvar. Also, in the future, we can create a function like &lt;em&gt;bexvar_from_table()&lt;/em&gt; which can read data from Stingray’s Lightcurve object and call &lt;em&gt;bexvar()&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In the next phase, I updated existing docstrings, added docstrings where it was missing, and worked on code formating. At this stage, the code was still failing in Stingray’s CI tests. The reason behind the failures was that the code uses an integrator &lt;a href="https://johannesbuchner.github.io/UltraNest/_modules/ultranest/integrator.html#ReactiveNestedSampler"&gt;&lt;strong&gt;ReactiveNestedSampler&lt;/strong&gt;&lt;/a&gt; from &lt;a href="https://arxiv.org/abs/2101.09604"&gt;UltraNest — a robust, general purpose Bayesian inference engine&lt;/a&gt;. UltraNest is not a required dependency for Stingray, hence CI tests were failing with import error. To resolve this, the import statement of UltraNest in bexvar.py needed to be moved inside a try-except statement. This would restrict the user from using bexvar.py if UltraNest is not installed. With this change, the code has passed the majority of CI tests.&lt;/p&gt;
&lt;p&gt;The overall experience of the coding period so far has been good. During this period I learned a lot about the essentials of open-source programming. I am learning to think like a programmer. I learned how small improvements in code make it more general and versatile. I learned about the best practices to write code. I must say that all this time my mentors Matteo and Daniela have been quite supportive and helpful. They have patiently listened to my queries and doubts and have always helped me with them.&lt;/p&gt;
&lt;p&gt;My code is running perfectly now, from this week onwards I will be focussing on writing tests for the code. Writing tests for a code is a completely new experience for me. I am looking forward to learn a lot about professional code testing in the following weeks. I will soon be back with a blog on my experience with testing. Till then take care! Goodbye!&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=f24a03c00014" width="1"&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220724_1811_mihirtripathi97/</guid><pubDate>Sun, 24 Jul 2022 17:11:57 GMT</pubDate></item><item><title>Implementing React Hook Form</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220724_0000_arunavabasu-03/</link><dc:creator>arunavabasu-03</dc:creator><description>&lt;p&gt;After analyzing the the benchmarks and taking with my mentors , we are decided to go with  React Hook Form  for it’s performace , low…&lt;/p&gt;
&lt;div style="margin-top: 50px; font-style: italic;"&gt;&lt;strong&gt;&lt;a href="https://minimal-blog.lekoarts.de/4th&amp;amp;5thWeek/"&gt;Keep reading&lt;/a&gt;.&lt;/strong&gt;&lt;/div&gt;&lt;br&gt; &lt;br&gt;
&lt;!-- TEASER_END --&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220724_0000_arunavabasu-03/</guid><pubDate>Sat, 23 Jul 2022 23:00:00 GMT</pubDate></item><item><title>Week 5 and Week 6</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220723_0000_supriya1702/</link><dc:creator>Supriya1702</dc:creator><description>&lt;p&gt;Entering into the 5th week I created a PR  https://github.com/radis/radis/pull/492   to address the task to add, retrieve and store the…&lt;/p&gt;
&lt;div style="margin-top: 50px; font-style: italic;"&gt;&lt;strong&gt;&lt;a href="https://minimal-blog.lekoarts.de/week-5-and-week-6"&gt;Keep reading&lt;/a&gt;.&lt;/strong&gt;&lt;/div&gt;&lt;br&gt; &lt;br&gt;
&lt;!-- TEASER_END --&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220723_0000_supriya1702/</guid><pubDate>Fri, 22 Jul 2022 23:00:00 GMT</pubDate></item><item><title>My GSoC Journey - Part 4</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220720_0000_jash-shah/</link><dc:creator>Jash Shah</dc:creator><description>&lt;p&gt;&lt;em&gt;Writing the extension modules and Python wrappers for a package is one thing, but a step that is often overlooked is making a build system that complies with the rest of your program, ensures the correct installation based on your dependencies and also is portable enough to be distributable.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I learned these things the hard way in Week 3 and 4, where I went as low level as I could to try to solve all the weird build errors and glitches I had while &lt;strong&gt;trying to build a Python Package using GNU Autotools&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="building"&gt;Building&lt;/h3&gt;
&lt;p&gt;As discussed in my last GSoC blog, I was mainly using &lt;code class="language-plaintext highlighter-rouge"&gt;distutils&lt;/code&gt; along with it’s &lt;code class="language-plaintext highlighter-rouge"&gt;distutils.setup&lt;/code&gt; script to take care of all the building and linking required for building the &lt;code class="language-plaintext highlighter-rouge"&gt;.so&lt;/code&gt; (shared object) file required by the  Python Interpreter. However, one of my co-mentors brought up a good point that &lt;code class="language-plaintext highlighter-rouge"&gt;setuptools&lt;/code&gt; is the packaging tool that is recommended by &lt;a href="https://packaging.python.org/en/latest/guides/tool-recommendations/"&gt;PyPA&lt;/a&gt; and also using &lt;code class="language-plaintext highlighter-rouge"&gt;wheels&lt;/code&gt; to package the modules instead of the standard &lt;code class="language-plaintext highlighter-rouge"&gt;setup.py build&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;Hence, &lt;strong&gt;Week 3 was spent mainly learning about &lt;code class="language-plaintext highlighter-rouge"&gt;setuptools&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;wheels&lt;/code&gt;&lt;/strong&gt;. &lt;a href="https://realpython.com/python-wheels/#the-manylinux-wheel-tag"&gt;What Are Python Wheels and Why Should You Care?&lt;/a&gt; is a great article to start with Python Wheels. The &lt;a href="https://setuptools.pypa.io/en/latest/index.html"&gt;setuptools documentation&lt;/a&gt; is a great place to know about setuptools, if you already know about distutils like me! Luckily, while &lt;code class="language-plaintext highlighter-rouge"&gt;Setuptools&lt;/code&gt; is a “beefier” version of distutils, as it offers better and more packaging utilities, it keeps the same functions, so in terms of code it was just a change of one line for me.&lt;/p&gt;

&lt;p&gt;Originally, with &lt;code class="language-plaintext highlighter-rouge"&gt;distutils&lt;/code&gt;, the plan was to have the files related to the Python Package in a separate &lt;em&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;python/&lt;/code&gt;&lt;/em&gt; directory at the root of the Gnuastro source like:&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;📦python
┣ 📂gnuastro.arithmetic
┃ ┣ 📜arithmetic.c
┃ ┗ 🔧setup.py
┣ 📂gnuastro.cosmology
┃ ┣ 📜cosmology.c
┃ ┗ 🔧setup.py
┣ 📂gnuastro.fits
┃ ┣ 📜fits.c
┃ ┗ 🔧setup.py
┗ 📑Makefile.am
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The idea was to have the &lt;code class="language-plaintext highlighter-rouge"&gt;setup.py&lt;/code&gt; script in each folder build that specific extension, and let the Makefile handle the linking. But I soon realized that this was too excessive. A better structure would be:&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt; 📦python
┣ 📂src
┃ ┣ 📜arithmetic.c
┃ ┣ 📜cosmology.c
┃ ┗ 📜fits.c
┣ 📑Makefile.am
┗ 🔧setup.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id="using-autotools-to-build-python-package"&gt;Using Autotools to build Python Package&lt;/h4&gt;
&lt;p&gt;As the name suggests &lt;strong&gt;GNU&lt;/strong&gt;astro is a GNU project, and thus depends on Autotools(&lt;a href="https://www.gnu.org/software/automake/manual/html_node/index.html#SEC_Contents"&gt;Automake&lt;/a&gt; and &lt;a href="https://www.gnu.org/software/autoconf/"&gt;Autoconf&lt;/a&gt; and &lt;a href="https://www.gnu.org/software/libtool/"&gt;Libtool&lt;/a&gt;) for its building and compiling. These are the tools behind the&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;./configure
make
make check
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;set of instructions.&lt;/p&gt;

&lt;p&gt;Alongwith the setup script, I also added a new file(&lt;a href="https://github.com/Jash-Shah/gnuastro-jash/blob/6997730fab6cb18fd7b34f77f9a0f65f0c7e0730/lib/python.c"&gt;&lt;code class="language-plaintext highlighter-rouge"&gt;python.c&lt;/code&gt;&lt;/a&gt;) to the &lt;em&gt;lib/&lt;/em&gt; directory of Gnuastro. This file basically provides any utility functions I might require while building the Python package. Currently, the file provides type conversion functions, which facilitate converting between Gnuastro and NumPy’s datatypes.&lt;/p&gt;

&lt;p&gt;So, what is the difference between your traditional Makefile and using Autotools instead:-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Autoconf&lt;/strong&gt; easily scans an existing tree to find its dependencies and creates a configure script that will run under almost any kind of shell. The configure script allows the user to control the build behavior (i.e. –with-foo, –without-python, –prefix, –sysconfdir, etc..) as well as doing checks to ensure that the system can compile the program.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Configure generates a &lt;code class="language-plaintext highlighter-rouge"&gt;config.h&lt;/code&gt; file (from a template) which programs can include to work around portability issues. For example, if HAVE_NUMPY is not defined, don’t build the Python package.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Automake&lt;/strong&gt; provides a short template that describes what programs will be built and what objects need to be linked to build them, thus Makefiles that adhere to GNU coding standards can automatically be created.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My job was to use these tools to also call the &lt;code class="language-plaintext highlighter-rouge"&gt;setup&lt;/code&gt; script for building my Python package.&lt;/p&gt;

&lt;p&gt;My approach to building the package using Autotools involved 4 basic steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Adding the necessary checks in the &lt;code class="language-plaintext highlighter-rouge"&gt;configure.ac&lt;/code&gt; script.
&lt;ul&gt;
&lt;li&gt;Check if a user has Python 3 on their system and get it’s include path i.e. path to &lt;code class="language-plaintext highlighter-rouge"&gt;Python.h&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;If Python 3 is found, Check if the user has NumPy on their system and get it’s include path.&lt;/li&gt;
&lt;li&gt;Substitute the include paths as variables to be passed to all &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am's&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conditionally build the Python package and its utility functions module(&lt;code class="language-plaintext highlighter-rouge"&gt;lib/python.c&lt;/code&gt;) only if the above checks are passed.&lt;/li&gt;
&lt;li&gt;Write the &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am&lt;/code&gt; in the &lt;code class="language-plaintext highlighter-rouge"&gt;python/&lt;/code&gt; directory which would handle the &lt;em&gt;build, install, uninstall and clean&lt;/em&gt; targets for the Python package.&lt;/li&gt;
&lt;li&gt;Re-write the setup.py script to make it more generic, by using the environment variables passed by the configure script instead of hardcoding the include and install paths.
&lt;ul&gt;
&lt;li&gt;This also ensures that the Python package building supports &lt;a href="https://www.gnu.org/software/automake/manual/html_node/VPATH-Builds.html"&gt;VPATH&lt;/a&gt; builds, which is another great feature of Autotools. For the uninitiated, &lt;code class="language-plaintext highlighter-rouge"&gt;VPATH builds&lt;/code&gt; are basically a way to separate your source and build tree, so that all the built files (.o, .so, etc) are in a separate directory than your source files but are symlinked to the source tree.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This process took a lot of trial and error, digging into the Autotools(mostly Automake) documentation and playing around with the &lt;code class="language-plaintext highlighter-rouge"&gt;Makefile.am&lt;/code&gt; to get right. But it introduced me to these amazing tools and taught me how to make any scrawny personal project distributable!&lt;/p&gt;

&lt;h3 id="installing"&gt;Installing&lt;/h3&gt;
&lt;p&gt;After running,&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;python3 setup.py build_ext bdist_wheel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the distributable wheel file, with all of the package’s metadata, is created under the &lt;code class="language-plaintext highlighter-rouge"&gt;dist/&lt;/code&gt; folder. In order to install this file we use pip as follows:&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;pip install Gnuastro.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;YES! It is in fact as simple as that!&lt;/p&gt;

&lt;p&gt;But there is an issue that I faced here, suppose that a user wants to install the Gnuastro library in their root directory, or to any directory where they dont have privileges. This means they’ll run &lt;code class="language-plaintext highlighter-rouge"&gt;sudo make install&lt;/code&gt; from the root of the source. This cascades to calling the Makefile in the &lt;em&gt;python/&lt;/em&gt; directory with root access as well. However, running &lt;code class="language-plaintext highlighter-rouge"&gt;pip&lt;/code&gt; with sudo access is a big NO, NO. And &lt;code class="language-plaintext highlighter-rouge"&gt;pip&lt;/code&gt; would warn you of that with a warning like:&lt;/p&gt;

&lt;p&gt;&lt;img alt="PIP sudo error message" height="50" src="https://jash-shah.github.io/Blogs/img/posts/gsoc-week3_4/pip_error.png" width="1000"&gt;&lt;/p&gt;

&lt;!-- ![PIP sudo error message](/Blogs/img/posts/gsoc-week3_4/pip_error.png) --&gt;

&lt;p&gt;This is because, Python packages are generally installed at a local level, in the &lt;code class="language-plaintext highlighter-rouge"&gt;/usr/local&lt;/code&gt; directory. However, if you call &lt;code class="language-plaintext highlighter-rouge"&gt;pip&lt;/code&gt; with &lt;code class="language-plaintext highlighter-rouge"&gt;sudo&lt;/code&gt; then it installs the packages in the root directory. To sove this, we use&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;sudo -u "$SUDO_USER pip install Gnuastro,whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which basically runs the pip command as the user who called sudo. This will ensure that your package gets installed in the local directory instead of root!&lt;/p&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220720_0000_jash-shah/</guid><pubDate>Tue, 19 Jul 2022 23:00:00 GMT</pubDate></item><item><title>GSoC 2022: Project Helioviewer — Facade for the API wrapper</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220718_0537_akash5100/</link><dc:creator>Akash</dc:creator><description>&lt;h4&gt;GSoC 2022: Project Helioviewer — Facade for the API wrapper&lt;/h4&gt;&lt;h4&gt;Week 3&lt;/h4&gt;&lt;p&gt;The Generic Function got merged with PR &lt;a href="https://github.com/Helioviewer-Project/python-api/pull/21"&gt;#21&lt;/a&gt;. This PR adds a function that accepts a URL Endpoint, Input Parameters (dictionary), and a descriptor of Output Parameters (what the endpoint is expected to return), which all the endpoint classes will inherit.&lt;/p&gt;
&lt;p&gt;This PR also includes the unittest for the Generic function and brings the first endpoint to the API wrapper, which is &lt;a href="https://hvpy.readthedocs.io/en/latest/api/hvpy.parameters.getJP2ImageInputParameters.html#getjp2imageinputparameters"&gt;&lt;strong&gt;getJP2Image&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;. &lt;/strong&gt;This endpoint retrieves a JP2000 image from the &lt;a href="http://helioviewer.org"&gt;helioviewer.org&lt;/a&gt; API.&lt;/p&gt;
&lt;h4&gt;Week 4&lt;/h4&gt;&lt;p&gt;The next task was to create a frontend for the &lt;strong&gt;getJP2Image &lt;/strong&gt;endpoint. The actual front end that users will interface with lives in a file called &lt;strong&gt;facade&lt;/strong&gt; which will hide this internal design. This module contains the API interface in its simplest form. It is responsible for taking user input, constructing the &lt;strong&gt;HvpyParameters &lt;/strong&gt;instance (the base class) and passing it to the &lt;strong&gt;core&lt;/strong&gt; to perform the request.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;View the code in:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;PR &lt;a href="https://github.com/Helioviewer-Project/python-api/pull/33"&gt;#33&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Week 5&lt;/h4&gt;&lt;p&gt;Finally, after the merging of the frontend function, we bring more JPEG2000 endpoints.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;PR &lt;a href="https://github.com/Helioviewer-Project/python-api/pull/34"&gt;#34&lt;/a&gt; — Adds the endpoint to the backend.&lt;/li&gt;&lt;li&gt;PR &lt;a href="https://github.com/Helioviewer-Project/python-api/pull/36"&gt;#36&lt;/a&gt; — Adds the frontend function.&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Week 6&lt;/h4&gt;&lt;p&gt;Still, a problem left to solve. There are several mirrors for Helioviewer and people might want to use a mirror instead of the main URL. So we will need to add a way to change this.&lt;/p&gt;
&lt;p&gt;PR &lt;a href="https://github.com/Helioviewer-Project/python-api/pull/41"&gt;#41&lt;/a&gt; closes this issue but it’s still under work. Hopefully, by the end of the week, it gets merged :)&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=69689b163879" width="1"&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220718_0537_akash5100/</guid><pubDate>Mon, 18 Jul 2022 04:37:22 GMT</pubDate></item><item><title>Fifth week - Major updates on literally everything, and non-LTE benchmarking</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220717_0000_tranhuunhathuy/</link><dc:creator>TranHuuNhatHuy</dc:creator><description>&lt;p&gt;&lt;a href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/b6a43fd435ed51da926a7346d2f66de9/JSON_sample.json"&gt;JSON sample&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;1. Fitting method benchmarking&lt;/h4&gt;
&lt;p&gt;The ideal of benchmarking result is to test and assess under what conditions, such as fitting method, pipeline, refinement, etc., the fitting process can achieve a stable and robust result. Firstly, I want to test the fitting method and see which ones are the best to put into the module as the default method. As we use LMFIT.Minimizer, we have 23 fitting methods in total:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;: Levenberg-Marquardt (default).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;least_squares&lt;/code&gt;: Least-Squares minimization, using Trust Region Reflective method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;differential_evolution&lt;/code&gt;: differential evolution.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;brute&lt;/code&gt;: brute force method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;basinhopping&lt;/code&gt;: Basin-hopping method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;ampgo&lt;/code&gt;: Adaptive Memory Programming for Global Optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;nelder&lt;/code&gt;: Nelder-Mead.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;: Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS-B).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;powell&lt;/code&gt;: Powell’s method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;cg&lt;/code&gt;: Conjugate-Gradient.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;newton&lt;/code&gt;: Newton-Conjugate-Gradient.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;cobyla&lt;/code&gt;: Cobyla.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;bfgs&lt;/code&gt;: Broyden–Fletcher–Goldfarb–Shanno (BFGS).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;tnc&lt;/code&gt;: Truncated Newton.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-ncg&lt;/code&gt;: Newton-Conjugate-Gradient trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-exact&lt;/code&gt;: nearly exact trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-krylov&lt;/code&gt;: Newton’s Generalized Lanczos Trust-Region (GLTR).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-constr&lt;/code&gt;: trust-region for constrained optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;dogleg&lt;/code&gt;: Dog-leg trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;slsqp&lt;/code&gt;: Sequential Linear Squares Programming.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;emcee&lt;/code&gt;: Maximum likelihood via Monte-Carlo Markov Chain.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;shgo&lt;/code&gt;: Simplicial Homology Global Optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;dual_annealing&lt;/code&gt;: Dual Annealing optimization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this list, there are 5 methods - &lt;code class="language-text"&gt;newton&lt;/code&gt;, &lt;code class="language-text"&gt;trust-ncg&lt;/code&gt;, &lt;code class="language-text"&gt;trust_exact&lt;/code&gt;, &lt;code class="language-text"&gt;trust-krylov&lt;/code&gt; and &lt;code class="language-text"&gt;dogleg&lt;/code&gt; - that require Jacobian function to work, which adds more complexity into our fitting process and codebase, hence I remove them from the benchmark and never use them again. There are also &lt;code class="language-text"&gt;emcee&lt;/code&gt; method that, for some unknown reasons, the fitting procedure never stops even after passing the loop limit, thus I have to remove it. Now we have 17 methods left that are stable enough to compare. Additionally, I set the max number of fitting loops as 200, so this means that any method that have equal of higher than 200 loops means that they are most likely unable to stop. I will conduct benchmarking process on the &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um.spec&lt;/code&gt; first.&lt;/p&gt;
&lt;p&gt;The result for this method-comparing benchmark can be found in &lt;a href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/method_comparison.txt"&gt;this JSON file&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Method&lt;/th&gt;
&lt;th align="center"&gt;Last residual&lt;/th&gt;
&lt;th align="center"&gt;Number of loops&lt;/th&gt;
&lt;th align="center"&gt;Processing time (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;leastsq&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042272&lt;/td&gt;
&lt;td align="center"&gt;17&lt;/td&gt;
&lt;td align="center"&gt;6.128568887710571&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;least_squares&lt;/td&gt;
&lt;td align="center"&gt;0.0027299046347&lt;/td&gt;
&lt;td align="center"&gt;14&lt;/td&gt;
&lt;td align="center"&gt;3.8792104721069336&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;differential_evolution&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042330&lt;/td&gt;
&lt;td align="center"&gt;48&lt;/td&gt;
&lt;td align="center"&gt;7.211840629577637&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;brute&lt;/td&gt;
&lt;td align="center"&gt;0.0027847218345&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;3.13600492477417&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;basinhopping&lt;/td&gt;
&lt;td align="center"&gt;0.0030471725482&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;31.650216579437256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ampgo&lt;/td&gt;
&lt;td align="center"&gt;0.0027301332094&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;36.60996413230896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;nelder&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042330&lt;/td&gt;
&lt;td align="center"&gt;48&lt;/td&gt;
&lt;td align="center"&gt;7.532714605331421&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;lbfgsb&lt;/td&gt;
&lt;td align="center"&gt;0.0027299043815&lt;/td&gt;
&lt;td align="center"&gt;12&lt;/td&gt;
&lt;td align="center"&gt;1.8955962657928467&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;powell&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042271&lt;/td&gt;
&lt;td align="center"&gt;38&lt;/td&gt;
&lt;td align="center"&gt;6.310025691986084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;cg&lt;/td&gt;
&lt;td align="center"&gt;0.0027299046922&lt;/td&gt;
&lt;td align="center"&gt;34&lt;/td&gt;
&lt;td align="center"&gt;5.223567724227905&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;cobyla&lt;/td&gt;
&lt;td align="center"&gt;0.0027299044752&lt;/td&gt;
&lt;td align="center"&gt;22&lt;/td&gt;
&lt;td align="center"&gt;3.028048515319824&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;bfgs&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042351&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;2.9560532569885254&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;tnc&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042284&lt;/td&gt;
&lt;td align="center"&gt;36&lt;/td&gt;
&lt;td align="center"&gt;5.905533313751221&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;trust-constr&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042271&lt;/td&gt;
&lt;td align="center"&gt;16&lt;/td&gt;
&lt;td align="center"&gt;2.3700413703918457&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;slsqp&lt;/td&gt;
&lt;td align="center"&gt;0.0027299969016&lt;/td&gt;
&lt;td align="center"&gt;18&lt;/td&gt;
&lt;td align="center"&gt;3.160074472427368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;shgo&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042272&lt;/td&gt;
&lt;td align="center"&gt;32&lt;/td&gt;
&lt;td align="center"&gt;6.185185194015503&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;dual_annealing&lt;/td&gt;
&lt;td align="center"&gt;0.0221619241989&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;32.40411591529846&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;(It is important to remember that this result might differ for each run, but rest assure the common trend is unchanged)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As you can see from the data above, we have &lt;code class="language-text"&gt;basinhopping&lt;/code&gt;, &lt;code class="language-text"&gt;ampgo&lt;/code&gt; and &lt;code class="language-text"&gt;dual_annealing&lt;/code&gt; jumping out of the loop limit of 200, and it’s totally not a good thing, which I would like to exclude them out for the sake of better visualization. Then, in order to compare the rest of 14 methods, I have a scatter plot below in which I focus on analyzing the &lt;code class="language-text"&gt;last_residual&lt;/code&gt; - indicator of accuracy - on the horizontal axis, and &lt;code class="language-text"&gt;loops&lt;/code&gt; - indicator of fitting iterations needed - on the vertical axis. As &lt;code class="language-text"&gt;time&lt;/code&gt; is heavily influenced by the computational capacity of each device, I don’t prioritize it than other two criteria in the result assessment, and thus it is indicated by color code.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Scatter plot of the result." src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/result_plot.png"&gt;&lt;/p&gt;
&lt;p&gt;If we zoom in the best 8 cases marked by the red rectangle above:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Best 8" src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/result_zoomed.png"&gt;&lt;/p&gt;
&lt;p&gt;In the zoomed figure, the result is quite satisfying as I expected. When we talk about the most famous curve-fitting algorithms, we can mention either &lt;code class="language-text"&gt;leastsq&lt;/code&gt;/&lt;code class="language-text"&gt;least_squares&lt;/code&gt; or &lt;code class="language-text"&gt;bfgs&lt;/code&gt;/&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;, and now we can see them taking 4 out of top 5. Now let’s focus on the two competitors: &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and &lt;code class="language-text"&gt;least_squares&lt;/code&gt; and get some observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; has a little lower residual and so a little bit better in accuracy than &lt;code class="language-text"&gt;least_squares&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Although approximately same fitting loops (12 and 14), the time required for &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; is 1.895596s, significantly lower than &lt;code class="language-text"&gt;least_squares&lt;/code&gt; of 3.879210s. We can also see this behavior in their neighbors: &lt;code class="language-text"&gt;bfgs&lt;/code&gt; (2.956053s) &amp;lt; &lt;code class="language-text"&gt;leastsq&lt;/code&gt; (6.128569s).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is explainable. While &lt;code class="language-text"&gt;least_squares&lt;/code&gt; simply calculating and minimizing the sum of the residuals of points from the comparative curves, &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; - Limited-memory BFGS uses a limited amount of computer memory to conduct &lt;a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm"&gt;Broyden-Fletcher-Goldfarb-Shanno algorithm&lt;/a&gt; for the minimization.&lt;/p&gt;
&lt;p&gt;So for now, I have initial assumption that &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; performs slightly better than &lt;code class="language-text"&gt;leastsq&lt;/code&gt;. After conducting fitting process on other spectra, the &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and &lt;code class="language-text"&gt;leastsq&lt;/code&gt; are seem to be dominant in terms of speed (based on number of loops and time elapsed) and accuracy (this depends a little bit on pipeline combination, which will be addressed in next part) compared to other methods. However, more benchmarks are needed to confirm my initla assumption.&lt;/p&gt;
&lt;h4&gt;2. Fitting pipeline comparison&lt;/h4&gt;
&lt;p&gt;Next is the benchmarking process focusing on pipeline comparison. A fitting pipeline comprises of several options, from spectrum refinement methods such as which spectral quantity to take, whether applying normalization on both spectra or not, or simply just fitting process preferences such as maxinum number of fitting loops allowed, or fitting method, or max fitting tolerance. While in the new JSON structure the users are free to adjust all of them, through this benchmarking process I would like acquire more understandings about how these pipeline might affect the quality of a fitting work.&lt;/p&gt;
&lt;p&gt;In order to assess a fitting’s quality, I use the synthetic spectra that I generated on week 1. Although they are heavily convoluted with noises and offsets, since they are software-generated, we can know what are the experimental properties (such as &lt;code class="language-text"&gt;path_length&lt;/code&gt;, &lt;code class="language-text"&gt;slit&lt;/code&gt;, etc.). Meanwhile, regarding the experimental spectrum &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um&lt;/code&gt;, we are definitely not sure those parameters (in fact, we don’t even know whether it is LTE or non-LTE). So, I decided to test on 7 synthetic spectra:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO-1-1800-2300-cm-1-P3-t1500-v-r-mf0.1-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-500-1100-cm-1-P2-t900-v-r-mf0.5-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-500-3000-cm-1-P93-t740-v-r-mf0.96-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-3300-3700-cm-1-P0.005-t3000-v-r-mf0.01-p1-sl1.4nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-H2O-1-1000-2500-cm-1-P0.5-t1500-v-r-mf0.5-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-NH3-1-500-2000-cm-1-P10-t1000-v-r-mf0.01-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-O2-1-7500-8000-cm-1-P1.01325-t298.15-v-r-mf0.21-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For each spectra, I will modify the pipeline’s &lt;code class="language-text"&gt;method&lt;/code&gt; and &lt;code class="language-text"&gt;normalize&lt;/code&gt; properties, until the best possible fitting result is achieved - least fitting loops, and closest to the ground-truth (GT) temperature (this is why I prefer synthetic over experimental spectra, as I explained above). Here is the result:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Spec No.&lt;/th&gt;
&lt;th align="center"&gt;GT Temp&lt;/th&gt;
&lt;th align="center"&gt;Start Temp&lt;/th&gt;
&lt;th align="center"&gt;Best Temp&lt;/th&gt;
&lt;th align="center"&gt;Method&lt;/th&gt;
&lt;th align="center"&gt;Normalize&lt;/th&gt;
&lt;th align="center"&gt;Diff&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1500&lt;/td&gt;
&lt;td align="center"&gt;1300&lt;/td&gt;
&lt;td align="center"&gt;1468.97&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/1.png"&gt;1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;2&lt;/td&gt;
&lt;td align="center"&gt;900&lt;/td&gt;
&lt;td align="center"&gt;1300&lt;/td&gt;
&lt;td align="center"&gt;898.84&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/2.png"&gt;2&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;3&lt;/td&gt;
&lt;td align="center"&gt;740&lt;/td&gt;
&lt;td align="center"&gt;1000&lt;/td&gt;
&lt;td align="center"&gt;~740&lt;/td&gt;
&lt;td align="center"&gt;both&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/3.png"&gt;3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;4&lt;/td&gt;
&lt;td align="center"&gt;3000&lt;/td&gt;
&lt;td align="center"&gt;2850&lt;/td&gt;
&lt;td align="center"&gt;3003.52&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/4.png"&gt;4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;1500&lt;/td&gt;
&lt;td align="center"&gt;2000&lt;/td&gt;
&lt;td align="center"&gt;1507.25&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;true&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/5.png"&gt;5&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;6&lt;/td&gt;
&lt;td align="center"&gt;1000&lt;/td&gt;
&lt;td align="center"&gt;2250&lt;/td&gt;
&lt;td align="center"&gt;994.90&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/6.png"&gt;6&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;7&lt;/td&gt;
&lt;td align="center"&gt;298.15&lt;/td&gt;
&lt;td align="center"&gt;660&lt;/td&gt;
&lt;td align="center"&gt;297.86&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/7.png"&gt;7&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see from the table above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All spectra achieve near-perfect best fit results. This is because we have perfect ground-truth conditions. In real-life circumstances, such accurate ground-truth is virtually impossible to achieve, but this is the job of fitting users to measure and set them.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt; performs quite good in most case. This is quite surprising after the result from &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um.spec&lt;/code&gt;, but it can be explained as most likely we didn’t use the correct ground-truth conditions for it since we don’t know (seriously, who created that spectrum?). However, there is a small observation from me that, those cases where &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; lost agains &lt;code class="language-text"&gt;leastsq&lt;/code&gt; were primarily because of number of loops. Still, it’s a win for &lt;code class="language-text"&gt;leastsq&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Their neighbors, &lt;code class="language-text"&gt;least_squares&lt;/code&gt; and &lt;code class="language-text"&gt;bfgs&lt;/code&gt;, are completely underdogs. We don’t even need to mention other methods.&lt;/li&gt;
&lt;li&gt;In nearly all the best cases, &lt;code class="language-text"&gt;normalize = false&lt;/code&gt; is set. This is quite explainable, the more originality the better.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Summary&lt;/h4&gt;
&lt;p&gt;After all the benchmarking works above, I have decided to set the &lt;code class="language-text"&gt;leastsq&lt;/code&gt; as the default fitting method, in case users don’t state the method explicitly in JSON file. Later on, in the fitting tutorial, I will add some suggestions about using &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and trying to switch the &lt;code class="language-text"&gt;normalize&lt;/code&gt; in case their fitting work is not quite good.&lt;/p&gt;
&lt;p&gt;Nevertheless, these benchmarks helped me gain more insights about the performance of my fitting module, and most importantly, let me experience the feeling of a spectroscopist trying to fit his spectra - playing around the parameters, adjusting parameters and praying for a good result to come. Quite a physically and mentally exhausting work to be honest, since whenever the result went wrong, I didn’t know whether the error came from ground-truth conditions, or from my fitting module. There have been days and nights I sat in front of my laptop adjusting the JSON files and codebase continuously. But finally, the benchmarking process for LTE spectra is good now, and I am quite confident in my fitting module. Now let’s move on to the non-LTE spectra!&lt;/p&gt;
&lt;p&gt;&lt;img alt="A footage of me turning parameters up and down like a DJ" src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/meme.jpg"&gt;&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220717_0000_tranhuunhathuy/</guid><pubDate>Sat, 16 Jul 2022 23:00:00 GMT</pubDate></item><item><title>Benchmarking and performance analysis</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220710_0000_arunavabasu-03/</link><dc:creator>arunavabasu-03</dc:creator><description>&lt;p&gt;Radis app uses  useState  to populate data and maintain state; while this works well for small scale applications, as it becomes better over…&lt;/p&gt;
&lt;div style="margin-top: 50px; font-style: italic;"&gt;&lt;strong&gt;&lt;a href="https://minimal-blog.lekoarts.de/3rdWeek"&gt;Keep reading&lt;/a&gt;.&lt;/strong&gt;&lt;/div&gt;&lt;br&gt; &lt;br&gt;
&lt;!-- TEASER_END --&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220710_0000_arunavabasu-03/</guid><pubDate>Sat, 09 Jul 2022 23:00:00 GMT</pubDate></item><item><title>Fourth week - Intensive benchmarking process for LTE spectra</title><link>http://openastronomy.org/Universe_OA/posts/2022/07/20220710_0000_tranhuunhathuy/</link><dc:creator>TranHuuNhatHuy</dc:creator><description>&lt;p&gt;As my fitting module has completed, now I am clear to start the benchmarking process. Initially, I planned to do it on 4 categories: large, small, LTE and non-LTE. But then, Mr. Erwan’s words helped me realize that my classification was somehow not ideal for this, as he said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The first need is not fitting performance, its a good fitting interface they would work on every typical condition.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Do not wasting time trying to determine a perfect threshold or categories.&lt;/p&gt;
&lt;p&gt;Work on real-life examples. CO2 4.2 - 5 µm is one.&lt;/p&gt;
&lt;p&gt;CO2 bandhead (the Single Temperature fit example) is another one.&lt;/p&gt;
&lt;p&gt;Works on the improving the fits from these real-life examples,
and - maybe - you’ll generalize to categories/classifications eventually.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To be honest, I have been thinking about changing my project timeline and objectives a little bit. Initially, I proposed the timeline in which I would spend 1 week for making the module, and 4 weeks to conduct benchmarking on 4 types of spectrum (large, small, LTE, non-LTE). But then, I encountered a lot of difficulties in conducting the fitting process, which significantly delays my fitting module to be completed in the end of week 3. Along with Mr. Erwan’s suggestions, after careful considerations, I have decided to reduce the category to only 2 groups of LTE and non-LTE spectra, and propose a new timeline based on that with my mentors, which successfully acquired their approvals. The new timeline is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Week 4 (this week): conduct benchmarking process on LTE spectra.&lt;/li&gt;
&lt;li&gt;Week 5: conduct benchmarking process on non-LTE spectra.&lt;/li&gt;
&lt;li&gt;Week 6: implement the fitting module and fitting models into RADIS codebase, finish any documentations, create a 101 tutorial, and prepare for first evaluation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this new timeline, the last week is going to be the toughest time ever! But I will try my best to catch up with the deadlines once and for all. I must admit that after half the first phase, I realized that my expected timeline in my project proposal - derived from my initial understandings of RADIS and fitting - is quite not applicable. As Mr. Minou - one of my mentors, said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don’t worry about changing the objectives . Some difficulties usually come up only when the project begins and cannot
be easily anticipated. New directions seem fine to me and you are on the right path.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As well as Mr. Erwan:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Just keep on progressing on the project as you do, reevaluating needs if needed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have more confidence in keeping on with my plan. This new approach, hopefully, will allow me to finish implementing the fitting module into RADIS by the end of first phase. Quite an intensive experience for me but, let’s go anyway! So here are the benchmarking results for our LTE experimental spectra, in which I will focus on comparison between fitting methods, and between refinement pipelines.&lt;/p&gt;
&lt;h4&gt;1. Fitting method benchmarking&lt;/h4&gt;
&lt;p&gt;The ideal of benchmarking result is to test and assess under what conditions, such as fitting method, pipeline, refinement, etc., the fitting process can achieve a stable and robust result. Firstly, I want to test the fitting method and see which ones are the best to put into the module as the default method. As we use LMFIT.Minimizer, we have 23 fitting methods in total:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;: Levenberg-Marquardt (default).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;least_squares&lt;/code&gt;: Least-Squares minimization, using Trust Region Reflective method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;differential_evolution&lt;/code&gt;: differential evolution.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;brute&lt;/code&gt;: brute force method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;basinhopping&lt;/code&gt;: Basin-hopping method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;ampgo&lt;/code&gt;: Adaptive Memory Programming for Global Optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;nelder&lt;/code&gt;: Nelder-Mead.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;: Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS-B).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;powell&lt;/code&gt;: Powell’s method.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;cg&lt;/code&gt;: Conjugate-Gradient.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;newton&lt;/code&gt;: Newton-Conjugate-Gradient.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;cobyla&lt;/code&gt;: Cobyla.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;bfgs&lt;/code&gt;: Broyden–Fletcher–Goldfarb–Shanno (BFGS).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;tnc&lt;/code&gt;: Truncated Newton.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-ncg&lt;/code&gt;: Newton-Conjugate-Gradient trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-exact&lt;/code&gt;: nearly exact trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-krylov&lt;/code&gt;: Newton’s Generalized Lanczos Trust-Region (GLTR).&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;trust-constr&lt;/code&gt;: trust-region for constrained optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;dogleg&lt;/code&gt;: Dog-leg trust-region.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;slsqp&lt;/code&gt;: Sequential Linear Squares Programming.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;emcee&lt;/code&gt;: Maximum likelihood via Monte-Carlo Markov Chain.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;shgo&lt;/code&gt;: Simplicial Homology Global Optimization.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;dual_annealing&lt;/code&gt;: Dual Annealing optimization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this list, there are 5 methods - &lt;code class="language-text"&gt;newton&lt;/code&gt;, &lt;code class="language-text"&gt;trust-ncg&lt;/code&gt;, &lt;code class="language-text"&gt;trust_exact&lt;/code&gt;, &lt;code class="language-text"&gt;trust-krylov&lt;/code&gt; and &lt;code class="language-text"&gt;dogleg&lt;/code&gt; - that require Jacobian function to work, which adds more complexity into our fitting process and codebase, hence I remove them from the benchmark and never use them again. There are also &lt;code class="language-text"&gt;emcee&lt;/code&gt; method that, for some unknown reasons, the fitting procedure never stops even after passing the loop limit, thus I have to remove it. Now we have 17 methods left that are stable enough to compare. Additionally, I set the max number of fitting loops as 200, so this means that any method that have equal of higher than 200 loops means that they are most likely unable to stop. I will conduct benchmarking process on the &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um.spec&lt;/code&gt; first.&lt;/p&gt;
&lt;p&gt;The result for this method-comparing benchmark can be found in &lt;a href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/43e71f48257a8a3d444d530c8859e77b/method_comparison.txt"&gt;this JSON file&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Method&lt;/th&gt;
&lt;th align="center"&gt;Last residual&lt;/th&gt;
&lt;th align="center"&gt;Number of loops&lt;/th&gt;
&lt;th align="center"&gt;Processing time (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;leastsq&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042272&lt;/td&gt;
&lt;td align="center"&gt;17&lt;/td&gt;
&lt;td align="center"&gt;6.128568887710571&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;least_squares&lt;/td&gt;
&lt;td align="center"&gt;0.0027299046347&lt;/td&gt;
&lt;td align="center"&gt;14&lt;/td&gt;
&lt;td align="center"&gt;3.8792104721069336&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;differential_evolution&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042330&lt;/td&gt;
&lt;td align="center"&gt;48&lt;/td&gt;
&lt;td align="center"&gt;7.211840629577637&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;brute&lt;/td&gt;
&lt;td align="center"&gt;0.0027847218345&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;3.13600492477417&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;basinhopping&lt;/td&gt;
&lt;td align="center"&gt;0.0030471725482&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;31.650216579437256&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ampgo&lt;/td&gt;
&lt;td align="center"&gt;0.0027301332094&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;36.60996413230896&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;nelder&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042330&lt;/td&gt;
&lt;td align="center"&gt;48&lt;/td&gt;
&lt;td align="center"&gt;7.532714605331421&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;lbfgsb&lt;/td&gt;
&lt;td align="center"&gt;0.0027299043815&lt;/td&gt;
&lt;td align="center"&gt;12&lt;/td&gt;
&lt;td align="center"&gt;1.8955962657928467&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;powell&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042271&lt;/td&gt;
&lt;td align="center"&gt;38&lt;/td&gt;
&lt;td align="center"&gt;6.310025691986084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;cg&lt;/td&gt;
&lt;td align="center"&gt;0.0027299046922&lt;/td&gt;
&lt;td align="center"&gt;34&lt;/td&gt;
&lt;td align="center"&gt;5.223567724227905&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;cobyla&lt;/td&gt;
&lt;td align="center"&gt;0.0027299044752&lt;/td&gt;
&lt;td align="center"&gt;22&lt;/td&gt;
&lt;td align="center"&gt;3.028048515319824&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;bfgs&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042351&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;2.9560532569885254&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;tnc&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042284&lt;/td&gt;
&lt;td align="center"&gt;36&lt;/td&gt;
&lt;td align="center"&gt;5.905533313751221&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;trust-constr&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042271&lt;/td&gt;
&lt;td align="center"&gt;16&lt;/td&gt;
&lt;td align="center"&gt;2.3700413703918457&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;slsqp&lt;/td&gt;
&lt;td align="center"&gt;0.0027299969016&lt;/td&gt;
&lt;td align="center"&gt;18&lt;/td&gt;
&lt;td align="center"&gt;3.160074472427368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;shgo&lt;/td&gt;
&lt;td align="center"&gt;0.0027299042272&lt;/td&gt;
&lt;td align="center"&gt;32&lt;/td&gt;
&lt;td align="center"&gt;6.185185194015503&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;dual_annealing&lt;/td&gt;
&lt;td align="center"&gt;0.0221619241989&lt;/td&gt;
&lt;td align="center"&gt;201&lt;/td&gt;
&lt;td align="center"&gt;32.40411591529846&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;(It is important to remember that this result might differ for each run, but rest assure the common trend is unchanged)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As you can see from the data above, we have &lt;code class="language-text"&gt;basinhopping&lt;/code&gt;, &lt;code class="language-text"&gt;ampgo&lt;/code&gt; and &lt;code class="language-text"&gt;dual_annealing&lt;/code&gt; jumping out of the loop limit of 200, and it’s totally not a good thing, which I would like to exclude them out for the sake of better visualization. Then, in order to compare the rest of 14 methods, I have a scatter plot below in which I focus on analyzing the &lt;code class="language-text"&gt;last_residual&lt;/code&gt; - indicator of accuracy - on the horizontal axis, and &lt;code class="language-text"&gt;loops&lt;/code&gt; - indicator of fitting iterations needed - on the vertical axis. As &lt;code class="language-text"&gt;time&lt;/code&gt; is heavily influenced by the computational capacity of each device, I don’t prioritize it than other two criteria in the result assessment, and thus it is indicated by color code.&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/41c56cdd9aa439841d66bb9a01dd543d/29114/result_plot.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="Scatter plot of the result." class="gatsby-resp-image-image" src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/41c56cdd9aa439841d66bb9a01dd543d/f058b/result_plot.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="Scatter plot of the result."&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we zoom in the best 8 cases marked by the red rectangle above:&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/b03e6b2a34c2ea21d9bc963c5d6e7acf/29114/result_zoomed.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="Best 8" class="gatsby-resp-image-image" src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/b03e6b2a34c2ea21d9bc963c5d6e7acf/f058b/result_zoomed.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="Best 8"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the zoomed figure, the result is quite satisfying as I expected. When we talk about the most famous curve-fitting algorithms, we can mention either &lt;code class="language-text"&gt;leastsq&lt;/code&gt;/&lt;code class="language-text"&gt;least_squares&lt;/code&gt; or &lt;code class="language-text"&gt;bfgs&lt;/code&gt;/&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;, and now we can see them taking 4 out of top 5. Now let’s focus on the two competitors: &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and &lt;code class="language-text"&gt;least_squares&lt;/code&gt; and get some observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; has a little lower residual and so a little bit better in accuracy than &lt;code class="language-text"&gt;least_squares&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Although approximately same fitting loops (12 and 14), the time required for &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; is 1.895596s, significantly lower than &lt;code class="language-text"&gt;least_squares&lt;/code&gt; of 3.879210s. We can also see this behavior in their neighbors: &lt;code class="language-text"&gt;bfgs&lt;/code&gt; (2.956053s) &amp;lt; &lt;code class="language-text"&gt;leastsq&lt;/code&gt; (6.128569s).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is explainable. While &lt;code class="language-text"&gt;least_squares&lt;/code&gt; simply calculating and minimizing the sum of the residuals of points from the comparative curves, &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; - Limited-memory BFGS uses a limited amount of computer memory to conduct &lt;a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm"&gt;Broyden-Fletcher-Goldfarb-Shanno algorithm&lt;/a&gt; for the minimization.&lt;/p&gt;
&lt;p&gt;So for now, I have initial assumption that &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; performs slightly better than &lt;code class="language-text"&gt;leastsq&lt;/code&gt;. After conducting fitting process on other spectra, the &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and &lt;code class="language-text"&gt;leastsq&lt;/code&gt; are seem to be dominant in terms of speed (based on number of loops and time elapsed) and accuracy (this depends a little bit on pipeline combination, which will be addressed in next part) compared to other methods. However, more benchmarks are needed to confirm my initla assumption.&lt;/p&gt;
&lt;h4&gt;2. Fitting pipeline comparison&lt;/h4&gt;
&lt;p&gt;Next is the benchmarking process focusing on pipeline comparison. A fitting pipeline comprises of several options, from spectrum refinement methods such as which spectral quantity to take, whether applying normalization on both spectra or not, or simply just fitting process preferences such as maxinum number of fitting loops allowed, or fitting method, or max fitting tolerance. While in the new JSON structure the users are free to adjust all of them, through this benchmarking process I would like acquire more understandings about how these pipeline might affect the quality of a fitting work.&lt;/p&gt;
&lt;p&gt;In order to assess a fitting’s quality, I use the synthetic spectra that I generated on week 1. Although they are heavily convoluted with noises and offsets, since they are software-generated, we can know what are the experimental properties (such as &lt;code class="language-text"&gt;path_length&lt;/code&gt;, &lt;code class="language-text"&gt;slit&lt;/code&gt;, etc.). Meanwhile, regarding the experimental spectrum &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um&lt;/code&gt;, we are definitely not sure those parameters (in fact, we don’t even know whether it is LTE or non-LTE). So, I decided to test on 7 synthetic spectra:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO-1-1800-2300-cm-1-P3-t1500-v-r-mf0.1-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-500-1100-cm-1-P2-t900-v-r-mf0.5-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-500-3000-cm-1-P93-t740-v-r-mf0.96-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-CO2-1-3300-3700-cm-1-P0.005-t3000-v-r-mf0.01-p1-sl1.4nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-H2O-1-1000-2500-cm-1-P0.5-t1500-v-r-mf0.5-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-NH3-1-500-2000-cm-1-P10-t1000-v-r-mf0.01-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;synth-O2-1-7500-8000-cm-1-P1.01325-t298.15-v-r-mf0.21-p1-sl1nm.spec&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For each spectra, I will modify the pipeline’s &lt;code class="language-text"&gt;method&lt;/code&gt; and &lt;code class="language-text"&gt;normalize&lt;/code&gt; properties, until the best possible fitting result is achieved - least fitting loops, and closest to the ground-truth (GT) temperature (this is why I prefer synthetic over experimental spectra, as I explained above). Here is the result:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Spec No.&lt;/th&gt;
&lt;th align="center"&gt;GT Temp&lt;/th&gt;
&lt;th align="center"&gt;Start Temp&lt;/th&gt;
&lt;th align="center"&gt;Best Temp&lt;/th&gt;
&lt;th align="center"&gt;Method&lt;/th&gt;
&lt;th align="center"&gt;Normalize&lt;/th&gt;
&lt;th align="center"&gt;Diff&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1500&lt;/td&gt;
&lt;td align="center"&gt;1300&lt;/td&gt;
&lt;td align="center"&gt;1468.97&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/1.png"&gt;1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;2&lt;/td&gt;
&lt;td align="center"&gt;900&lt;/td&gt;
&lt;td align="center"&gt;1300&lt;/td&gt;
&lt;td align="center"&gt;898.84&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;lbfgsb&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/2.png"&gt;2&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;3&lt;/td&gt;
&lt;td align="center"&gt;740&lt;/td&gt;
&lt;td align="center"&gt;1000&lt;/td&gt;
&lt;td align="center"&gt;~740&lt;/td&gt;
&lt;td align="center"&gt;both&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/3.png"&gt;3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;4&lt;/td&gt;
&lt;td align="center"&gt;3000&lt;/td&gt;
&lt;td align="center"&gt;2850&lt;/td&gt;
&lt;td align="center"&gt;3003.52&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/4.png"&gt;4&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;1500&lt;/td&gt;
&lt;td align="center"&gt;2000&lt;/td&gt;
&lt;td align="center"&gt;1507.25&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;true&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/5.png"&gt;5&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;6&lt;/td&gt;
&lt;td align="center"&gt;1000&lt;/td&gt;
&lt;td align="center"&gt;2250&lt;/td&gt;
&lt;td align="center"&gt;994.90&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/6.png"&gt;6&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;7&lt;/td&gt;
&lt;td align="center"&gt;298.15&lt;/td&gt;
&lt;td align="center"&gt;660&lt;/td&gt;
&lt;td align="center"&gt;297.86&lt;/td&gt;
&lt;td align="center"&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt;&lt;/td&gt;
&lt;td align="center"&gt;false&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/TranHuuNhatHuy/my-2022-gsoc-journey/master/content/blog/5.%204th-week/7.png"&gt;7&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we can see from the table above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All spectra achieve near-perfect best fit results. This is because we have perfect ground-truth conditions. In real-life circumstances, such accurate ground-truth is virtually impossible to achieve, but this is the job of fitting users to measure and set them.&lt;/li&gt;
&lt;li&gt;&lt;code class="language-text"&gt;leastsq&lt;/code&gt; performs quite good in most case. This is quite surprising after the result from &lt;code class="language-text"&gt;CO2_measured_spectrum_4-5um.spec&lt;/code&gt;, but it can be explained as most likely we didn’t use the correct ground-truth conditions for it since we don’t know (seriously, who created that spectrum?). However, there is a small observation from me that, those cases where &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; lost agains &lt;code class="language-text"&gt;leastsq&lt;/code&gt; were primarily because of number of loops. Still, it’s a win for &lt;code class="language-text"&gt;leastsq&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Their neighbors, &lt;code class="language-text"&gt;least_squares&lt;/code&gt; and &lt;code class="language-text"&gt;bfgs&lt;/code&gt;, are completely underdogs. We don’t even need to mention other methods.&lt;/li&gt;
&lt;li&gt;In nearly all the best cases, &lt;code class="language-text"&gt;normalize = false&lt;/code&gt; is set. This is quite explainable, the more originality the better.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Summary&lt;/h4&gt;
&lt;p&gt;After all the benchmarking works above, I have decided to set the &lt;code class="language-text"&gt;leastsq&lt;/code&gt; as the default fitting method, in case users don’t state the method explicitly in JSON file. Later on, in the fitting tutorial, I will add some suggestions about using &lt;code class="language-text"&gt;lbfgsb&lt;/code&gt; and trying to switch the &lt;code class="language-text"&gt;normalize&lt;/code&gt; in case their fitting work is not quite good.&lt;/p&gt;
&lt;p&gt;Nevertheless, these benchmarks helped me gain more insights about the performance of my fitting module, and most importantly, let me experience the feeling of a spectroscopist trying to fit his spectra - playing around the parameters, adjusting parameters and praying for a good result to come. Quite a physically and mentally exhausting work to be honest, since whenever the result went wrong, I didn’t know whether the error came from ground-truth conditions, or from my fitting module. There have been days and nights I sat in front of my laptop adjusting the JSON files and codebase continuously. But finally, the benchmarking process for LTE spectra is good now, and I am quite confident in my fitting module. Now let’s move on to the non-LTE spectra!&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/83691995f7e77035e5034ccbfb1a61ff/41099/meme.jpg" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="A footage of me turning parameters up and down like a DJ" class="gatsby-resp-image-image" src="https://gsoc2022tranhuunhathuy.gatsbyjs.io/static/83691995f7e77035e5034ccbfb1a61ff/41099/meme.jpg" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="A footage of me turning parameters up and down like a DJ"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2022/07/20220710_0000_tranhuunhathuy/</guid><pubDate>Sat, 09 Jul 2022 23:00:00 GMT</pubDate></item></channel></rss>